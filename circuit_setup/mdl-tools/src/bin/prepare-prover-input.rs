// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.

// This program parses a CBOR-encoded mDL and tests extracting the required information
// to generate the ZK circuit inputs.
//
// Usage:
//    prepare-prover-input --config <config> --mdl <mdl> --prover_inputs <prover_inputs>
// where
//    <config> is a JSON file containing the configuration
//    <mdl> is a CBOR-encoded mDL
//    <prover_inputs> is the output JSON file containing the prover inputs
//
// Notes:
//    - The mDL file can be generated by the mdl-gen program
//    - To test: cargo run --bin mdl-test -- --config ../inputs/mdl1/config.json --mdl ../inputs/mdl1/mdl.cbor --prover_inputs ../generated_files/mdl1/prover_inputs.json

// TODO: simplify this file by using similar functions from creds/src/prep_inputs.rs

use anyhow::Result;
use clap::Parser;
use coset::cbor::Value;
use coset::Label;
use isomdl::cbor;
use isomdl::definitions::helpers::{ByteStr, NonEmptyVec};
use isomdl::definitions::issuer_signed::IssuerSignedItemBytes;
use isomdl::definitions::x509::x5chain::X5CHAIN_COSE_HEADER_LABEL;
use isomdl::definitions::x509::X5Chain;
use isomdl::definitions::{DigestAlgorithm, DigestId, Mso};
use isomdl::issuance::mdoc::Mdoc;
use p256::ecdsa::{Signature, VerifyingKey};
use p256::pkcs8::EncodePublicKey;
use p256::NistP256;
use serde_json::Map;
use sha2::{Digest, Sha256};
use base64::{engine::general_purpose::URL_SAFE_NO_PAD, Engine};
use num_bigint::BigUint;
use num_traits::{Num, Zero, One, ToPrimitive};
use chrono::{DateTime, Datelike, FixedOffset, NaiveDate, NaiveDateTime, TimeZone, Utc};
use std::str;
use std::collections::BTreeMap;

static MDL_DOCTYPE: &str = "org.iso.18013.5.1.mDL";
static ISO_MDL_NAMESPACE: &str = "org.iso.18013.5.1";
static AAMVA_MDL_NAMESPACE: &str = "org.iso.18013.5.1.aamva";
static SUPPORTED_NAMESPACES: [&str; 2] = [ISO_MDL_NAMESPACE, AAMVA_MDL_NAMESPACE];
const CIRCOM_ES256_LIMB_BITS: usize = 43;

// Define the issuer's timezone as PST (UTC-8). Change this if needed (TODO: move to config)
const ISSUER_TIMEZONE_OFFSET_HOURS: i32 = -8; // US West Coast / PST (UTC-8)

#[derive(Parser, Debug)]
#[command(author, version, about)]
struct Args {
    /// JSON file containing the config
    #[arg(short = 'c', long = "config")]
    config: String,

    /// JSON file containing the mDL ISO claims
    #[arg(short = 'm', long = "mdl")]
    mdl: String,

    /// output JSON file containing the prover inputs
    #[arg(short = 'i', long = "prover_inputs")]
    prover_inputs: String,
}

fn sha256_padding(prepad_m: &[u8]) -> Vec<u8> {
    let msg_length_bits = (prepad_m.len() * 8) as u32;
    
    // Start with prepad_m and add the 0x80 (128 in decimal) padding byte
    let mut padded_m = prepad_m.to_vec();
    padded_m.push(0x80);

    // Pad with zeros until the total length + 4 bytes (32-bit message length) is a multiple of 64 bytes (512 bits)
    while (padded_m.len() + 4) * 8 % 512 != 0 {
        padded_m.push(0);
    }

    // Append the message length as a 4-byte big-endian value
    padded_m.extend_from_slice(&msg_length_bits.to_be_bytes());

    padded_m
}

fn hex_string_to_binary_array(hex_str: &str, bits: usize) -> Vec<u8> {
    let num = BigUint::from_str_radix(hex_str, 16)
    .expect("Invalid hex string");
    let binary_string = format!("{:0>bits$b}", num, bits = bits);    
    binary_string
        .chars()
        .map(|b| b.to_digit(2).unwrap() as u8)
        .collect()
}

fn digest_to_limbs(digest_hex: &str) -> [u128; 2] {
    let digest_bytes = hex::decode(digest_hex).expect("Invalid hex string");
    let n = u128::from_be_bytes(digest_bytes[0..16].try_into().unwrap());
    let b = u128::from_be_bytes(digest_bytes[16..32].try_into().unwrap());
    [n, b]
}

fn base64_decoded_size(encoded_len: usize) -> usize {
    encoded_len.div_ceil(4) * 3
}

fn ymd_to_timestamp(ymd: &str, is_bytes: bool, has_time: bool) -> Option<u64> {
    // Decode hex if necessary.
    let ymd_str = if is_bytes {
        hex::decode(ymd)
            .ok()
            .and_then(|decoded| String::from_utf8(decoded).ok())?
    } else {
        ymd.to_string()
    };

    // Determine the format string.
    let format_string = if has_time {
        "%Y-%m-%dT%H:%M:%SZ"
    } else {
        "%Y-%m-%d"
    };

    // Parse the date/time from the string.
    let naive_dt = NaiveDateTime::parse_from_str(&ymd_str, format_string).ok()?;

    // Reset time-of-day to midnight.
    let midnight = naive_dt.date().and_hms_opt(0, 0, 0).unwrap();

    // Build the correct FixedOffset.
    let offset_secs = ISSUER_TIMEZONE_OFFSET_HOURS * 3600;
    let fixed_offset = if offset_secs < 0 {
        FixedOffset::west_opt(-offset_secs)?
    } else {
        FixedOffset::east_opt(offset_secs)?
    };

    // Convert the naive datetime to a timezone-aware datetime.
    let dt_fixed = fixed_offset.from_local_datetime(&midnight).single()?;
    // Convert to UTC and return the timestamp.
    let dt_utc: DateTime<Utc> = dt_fixed.with_timezone(&Utc);
    Some(dt_utc.timestamp() as u64)
}

fn ymd_to_daystamp(ymd: &str) -> Option<i32> {
    let parsed_date = NaiveDate::parse_from_str(ymd, "%Y-%m-%d").ok()?;
    Some(parsed_date.num_days_from_ce())
}

#[derive(Debug)]
struct  ValueDigestInfo {
    value: Value,
    id: DigestId,
    digest: Vec<u8>,
    preimage: ByteStr,
    encoded_l: usize,
    encoded_r: usize,
}

/// Returns (encoded_l, encoded_r) as computed from tbs_data.
///
/// The CBOR format is:
/// - 2-digit hex for the digest id (e.g. "13" for 19) // FIXME: this assumes the id is < 23 (otherwise CBOR encodes it in 2 bytes)
/// - Literal "5820" for a 32-byte byte string indicator
/// - The 32-byte SHA-256 digest in hex (64 hex digits)
///
/// Then we find the position of this string in the hex-encoded tbs_data. Each byte is 2 hex digits,
/// so we convert the found index to a byte index (by dividing by 2) and subtract 1 (to adjust for a header).
/// Finally, encoded_r is computed as encoded_l + (length of cbored_digest in bytes).
pub fn compute_encoded_positions(
    tbs_data: &[u8],
    digest_id: DigestId,
    digest: &[u8],
) -> Result<(usize, usize), String> {
    // Build the "cbored_digest" string.
    // - Format: "{:02x}5820{}", where {:02x} is the digest id in 2-digit hex,
    //   "5820" is a literal string, and the digest is hex-encoded.
    // FIXME: bending over backward to convert the digest_id into a value accepted by format()
    //         Digest is defined as "pub struct DigestId(i32)" and provide no public accessor
    //         to the i32.
    let id_i32: i32 = serde_json::from_str(&serde_json::to_string(&digest_id).unwrap()).unwrap();
    let cbored_digest = format!("{:02x}5820{}", id_i32, hex::encode(digest));
    
    // Convert the entire tbs_data into a hex string.
    let tbs_data_hex = hex::encode(tbs_data);
    
    // Find the start position of cbored_digest within tbs_data_hex.
    // This position is in terms of hex characters.
    let pos = tbs_data_hex.find(&cbored_digest)
        .ok_or("cbored_digest not found in tbs_data")?;
    
    // Each byte is represented by 2 hex characters.
    // So, convert the position from hex characters to byte index and subtract 1.
    let encoded_l = pos / 2;

    // The length of cbored_digest in bytes is its length (in hex characters) divided by 2.
    let encoded_r = encoded_l + (cbored_digest.len() / 2);
    
    Ok((encoded_l, encoded_r))
}

/// Given an mdoc and a target element name, recompute the value digest,
/// compare it with the signed digest in the mso, and return detailed info.
pub(crate) fn find_value_digest_info(
    namespaces: &BTreeMap<String, NonEmptyVec<IssuerSignedItemBytes>>,
    mso: &Mso,
    tbs_data: &[u8],
    claim: &str,
) -> Option<ValueDigestInfo> {

    let mut info = ValueDigestInfo {
        value: Value::Null,
        id: DigestId::new(0),
        digest: Vec::new(),
        preimage: ByteStr::from(Vec::new()),
        encoded_l: 0,
        encoded_r: 0,
    };

    // Iterate over each supported namespace.
    for &ns in SUPPORTED_NAMESPACES.iter() {
        if let Some(items) = namespaces.get(ns) {
            // items is a NonEmptyVec<IssuerSignedItemBytes>; iterate over its items.
            for item in items.iter() {
                if item.as_ref().element_identifier != claim {
                    continue;
                }
                println!("found claim: {}", claim);
                println!("item: {:?}", item);

                info.value = item.as_ref().element_value.clone();
                println!("value: {:?}", info.value);
                info.id = item.as_ref().digest_id;
                info.preimage = ByteStr::from(isomdl::cbor::to_vec(item).expect("unable to encode IssuerSigned as cbor bytes"));
                let mut hasher = Sha256::new();
                hasher.update(&info.preimage);
                let recomputed_value_digest = hasher.finalize().to_vec();
                // print recomputed digest as hex
                println!("Recomputed digest: {}", hex::encode(&recomputed_value_digest));
                let ns_digests = mso.value_digests.get(ns)
                    .ok_or(format!("Namespace {} not found", ns)).unwrap();
                let signed_value_digest = ns_digests.get(&info.id)
                    .ok_or(format!("Signed value digest not found for digest id {:?}", info.id)).unwrap();
                println!("signed_value_digest: {:?}", hex::encode(signed_value_digest));
                // Compare recomputed digest with the signed digest.
                if recomputed_value_digest != signed_value_digest.as_ref()  {
                    println!("Digest mismatch");
                    println!("Recomputed: {}", hex::encode(&recomputed_value_digest));
                    println!("Signed    : {}", hex::encode(signed_value_digest));
                    panic!("Digest mismatch");
                } else {
                    println!("Digest: {}", hex::encode(&recomputed_value_digest));
                }
                info.digest = signed_value_digest.as_ref().to_vec();
                let encoded_pos = compute_encoded_positions(tbs_data, info.id, &info.digest).unwrap();
                info.encoded_l = encoded_pos.0;
                info.encoded_r = encoded_pos.1;
                return Some(info)
            }
        }
    }
    
    println!("Claim not found: {}", claim);
    None
}

// TODO: see the check_config() function in the python script; more stuff to implement
fn check_config(config: &serde_json::Value) {
    // check the credtype
    let credtype = config["credtype"].as_str().unwrap();
    if credtype != "mdl" {
        panic!("Invalid credtype: {}", credtype);
    }

    // check the signature alg
    let alg = config["alg"].as_str().unwrap();
    if alg != "ES256" {
        panic!("Unsupported alg: {}", alg);
    }

    // make sure max_cred_len exists
    let max_cred_len = config["max_cred_len"].as_u64().unwrap();
    if max_cred_len == 0 {
        panic!("Invalid max_cred_len, needs to be > 0: {}", max_cred_len);
    }
}

fn bytes_to_circom_limbs(bytes: &[u8], limb_size: usize) -> Vec<u128> {
    let n = BigUint::from_bytes_be(bytes);
    let mut limbs = Vec::new();
    // Create a BigUint mask: (1 << limb_size) - 1
    let msk = (BigUint::one() << limb_size) - BigUint::one();
    let mut n_copy = n.clone();
    
    while n_copy > BigUint::zero() {
        // Use the BigUint mask in the bitwise AND operation
        let limb = (n_copy.clone() & msk.clone()).to_u128().unwrap();
        limbs.push(limb);
        n_copy >>= limb_size;
    }
    
    limbs
}

fn main() {
    let args = Args::parse();

    // read and parse the config file
    let config_file = std::fs::read_to_string(&args.config).unwrap();
    let config: serde_json::Value = serde_json::from_str(&config_file).unwrap();
    check_config(&config);

    let mdl_cbor = std::fs::read(&args.mdl).unwrap();
    let mdoc = cbor::from_slice::<Mdoc>(
        &mdl_cbor)
        .map_err(|_| "Failed to parse mDL")
        .unwrap();

    let doc_type = mdoc.doc_type;
    println!("doc_type: {}\n", doc_type);
    if doc_type != MDL_DOCTYPE {
        panic!("Invalid mDL doc type: {}", doc_type);
    }
    
    // TODO: anything to do with the MSO?
    let mso = mdoc.mso;
    // make sure the digest alg is SHA256. No compare or public accessor on the DigestAlgorithm enum, so
    // I need to serialize it to compare its value.
    if !matches!(mso.digest_algorithm, DigestAlgorithm::SHA256) {
        panic!("Unsupported MSO digest algorithm: {:?}, expected SHA-256", mso.digest_algorithm)
    }
    // TODO: we might need these digests in the future, for selective disclosure
    let _value_digests = &mso.value_digests;

    let namespaces = mdoc.namespaces;
    for (key, value) in namespaces.iter() {
        if !SUPPORTED_NAMESPACES.contains(&key.as_str()) {
            panic!("Invalid mDL namespace: {}", key);
        }
        println!("{} namespace claim count: {}\n", key, value.len());
    }
    
    let issuer_auth = mdoc.issuer_auth;

    // issuer_auth fields
    let unprotected_header = issuer_auth.unprotected.clone();
    let x5chain = unprotected_header
        .rest
        .iter()
        .find(|(label, _)| label == &Label::Int(X5CHAIN_COSE_HEADER_LABEL))
        .map(|(_, value)| value.to_owned())
        .map(X5Chain::from_cbor)
        .unwrap()
        .unwrap();

    let issuer_pub_key = x5chain.end_entity_public_key::<NistP256>().unwrap();
    let _pem = issuer_pub_key
        .to_public_key_pem(Default::default())
        .unwrap();

    // per mDL spec, aad is empty
    let empty_aad = Vec::<u8>::new();
    let tbs_data = issuer_auth.inner.tbs_data(&empty_aad);

    // convert tbs_data to a vector of integers
    let tbs_data_ints = tbs_data.to_vec();
    println!("tbs_data_ints length: {:?}\n", tbs_data_ints.len());

    // convert header and payload to UTF-8 integers in base-10 (e.g., 'e' -> 101, 'y' -> 121, ...)
    let padded_m = sha256_padding(&tbs_data_ints);
    let msg_len_after_sha2_padding = padded_m.len();
    println!("msg_len_after_SHA2_padding: {:?}\n", msg_len_after_sha2_padding);

    let config_max_cred_len = config["max_cred_len"].as_u64().unwrap() as usize;
    if msg_len_after_sha2_padding > config_max_cred_len {
        println!(
            "Error: mDL too large. Current mDL header + payload is {} bytes ({} bytes after SHA256 padding), but maximum length supported is {} bytes.",
            tbs_data_ints.len(),
            msg_len_after_sha2_padding,
            base64_decoded_size(config_max_cred_len)
        );
        println!(
            "The config file value `max_cred_len` would have to be increased to {} bytes (currently config['max_cred_len'] = {})",
            tbs_data_ints.len() + 64,
            config_max_cred_len
        );
        std::process::exit(-1);
    }

    let mut padded_m_extended = Vec::with_capacity(config_max_cred_len);
    padded_m_extended.extend_from_slice(&padded_m);
    padded_m_extended.resize(config_max_cred_len, 0);

    let mut hasher = Sha256::new();
    hasher.update(&tbs_data_ints);
    let sha256_hash = hasher.finalize();

    let digest_hex_str = hex::encode(sha256_hash);
    let _digest_bits = hex_string_to_binary_array(&digest_hex_str, 256); // FIXME: from python script, but unused
    let _digest_b64 = URL_SAFE_NO_PAD.encode(sha256_hash); // FIXME: from python script, but unused
    let _digest_limbs = digest_to_limbs(&digest_hex_str); // FIXME: from python script, but unused
    
    let valid_until_prefix = "6a76616c6964556e74696cc074"; // 6a: text(10), 7661...696c: "validUntil", c0: date, 74: text(20)
    let tbs_data_hex = hex::encode(&tbs_data);
    let valid_until_prefix_pos = tbs_data_hex.find(valid_until_prefix).unwrap();
    let valid_until_pos = valid_until_prefix_pos + valid_until_prefix.len();
    let valid_until_data = &tbs_data_hex[valid_until_pos..valid_until_pos + 40];
    let valid_until_unix_timestamp = ymd_to_timestamp(valid_until_data, true, true).unwrap();
    println!("valid_until_unix_timestamp: {}", valid_until_unix_timestamp);

    let dob_info = find_value_digest_info(&namespaces, &mso, &tbs_data, "birth_date").unwrap();
    println!("dob_info: {:?}", dob_info);

    // begin output of prover's inputs
    let mut prover_inputs = Map::new();
    prover_inputs.insert("message".to_string(), serde_json::json!(padded_m_extended));
    prover_inputs.insert("valid_until_value".to_string(), serde_json::json!(valid_until_unix_timestamp));
    let valid_until_prefix_l = valid_until_prefix_pos / 2;
    prover_inputs.insert("valid_until_prefix_l".to_string(), valid_until_prefix_l.into());
    let valid_until_prefix_r = valid_until_prefix_l + valid_until_prefix.len() / 2;
    prover_inputs.insert("valid_until_prefix_r".to_string(), valid_until_prefix_r.into());
    let dob_value = ymd_to_daystamp(dob_info.value.into_tag().unwrap().1.into_text().unwrap().as_str()).unwrap();
    prover_inputs.insert("dob_value".to_string(), serde_json::json!(dob_value));
    prover_inputs.insert("dob_id".to_string(), serde_json::json!(dob_info.id));
    let dob_preimage = sha256_padding(dob_info.preimage.as_ref());
    if dob_preimage.len() != 128 {
        panic!("Invalid dob_preimage length: {}; expected 128 (hardcoded in circom circuit)", dob_preimage.len());
    }
    prover_inputs.insert("dob_preimage".to_string(), serde_json::json!(dob_preimage));
    prover_inputs.insert("dob_encoded_l".to_string(), serde_json::json!(dob_info.encoded_l));
    prover_inputs.insert("dob_encoded_r".to_string(), serde_json::json!(dob_info.encoded_r));

    // extract the signature from the issuer_auth
    let signature_bytes = issuer_auth.signature.clone();

    // sanity check: verify the signature
    let verification_result =
            issuer_auth
            .verify::<VerifyingKey, Signature>(&issuer_pub_key, None, None);
    if !verification_result.is_success() {
        panic!("Error: issuer signature verification failed: {}", verification_result.into_result().err().unwrap());
    }

    // process the signature
    // See https://www.rfc-editor.org/rfc/rfc7515#appendix-A.3.1 for ECDSA encoding details, the signature is R||S
    // this code assumes |R|==|S|
    let sig_len = signature_bytes.len();
    if sig_len % 2 != 0 {
        panic!("Invalid signature length: {}", sig_len);
    }
    let r_bytes = &signature_bytes[0..sig_len / 2];
    let s_bytes = &signature_bytes[sig_len / 2..sig_len];
    let r_limbs = bytes_to_circom_limbs(r_bytes, CIRCOM_ES256_LIMB_BITS);
    let s_limbs = bytes_to_circom_limbs(s_bytes, CIRCOM_ES256_LIMB_BITS);
    prover_inputs.insert("signature_r".to_string(), serde_json::json!(r_limbs));
    prover_inputs.insert("signature_s".to_string(), serde_json::json!(s_limbs));

    // process the issuer public key
    let issuer_key_bytes = issuer_pub_key.to_sec1_bytes();
    if issuer_key_bytes[0] != 0x04 {
        panic!("Invalid serialized issuer public key format: {}, expected uncompressed marker 0x04", issuer_key_bytes[0]);
    }
    if issuer_key_bytes.len() != 65 {
        panic!("Invalid serialized issuer public key length: {}", issuer_key_bytes.len());
    }
    // skipping the first byte (0x04) which indicates the key is uncompressed
    let issuer_key_x = &issuer_key_bytes[1..33];
    let issuer_key_y = &issuer_key_bytes[33..65];
    let x_limb = bytes_to_circom_limbs(issuer_key_x, CIRCOM_ES256_LIMB_BITS);
    let y_limb = bytes_to_circom_limbs(issuer_key_y, CIRCOM_ES256_LIMB_BITS);
    prover_inputs.insert("pubkey_x".to_string(), serde_json::json!(x_limb));
    prover_inputs.insert("pubkey_y".to_string(), serde_json::json!(y_limb));
    prover_inputs.insert("message_padded_bytes".to_string(), msg_len_after_sha2_padding.into());
    println!("Number of SHA blocks to hash: {}\n", msg_len_after_sha2_padding);

    // the python script defines a public_IOs and prover_aux_data dictionaries, but never write them out (FIXME) 

    // save prover_inputs to a file
    let prover_inputs_json = serde_json::to_string_pretty(&prover_inputs).unwrap();
    std::fs::write(&args.prover_inputs, prover_inputs_json).unwrap();
    println!("Prover inputs saved to: {}\n", args.prover_inputs);
}
