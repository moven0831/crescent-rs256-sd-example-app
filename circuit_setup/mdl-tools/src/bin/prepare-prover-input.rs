// Copyright (c) Microsoft Corporation.
// Licensed under the MIT license.

// This program parses a CBOR-encoded mDL and tests extracting the required information
// to generate the ZK circuit inputs.
//
// Usage:
//    prepare-prover-input --config <config> --mdl <mdl> --prover_inputs <prover_inputs>
// where
//    <config> is a JSON file containing the configuration
//    <mdl> is a CBOR-encoded mDL
//    <prover_inputs> is the output JSON file containing the prover inputs
//    <prover_aux> is the output JSON file containing the prover auxiliary data
//
// Notes:
//    - The mDL file can be generated by the mdl-gen program
//    - To test: cargo run --bin prepare-prover-input -- --config ../inputs/mdl1/config.json --mdl ../inputs/mdl1/mdl.cbor --prover_inputs ../generated_files/mdl1/prover_inputs.json --prover_aux ../generated_files/mdl1/prover_aux.json

// TODO: simplify this file by using similar functions from creds/src/prep_inputs.rs

use anyhow::Result;
use clap::Parser;
use coset::cbor::Value;
use coset::iana::Algorithm;
use coset::Label;
use lazy_static::lazy_static;
use isomdl::cbor;
use isomdl::definitions::helpers::{ByteStr, NonEmptyVec};
use isomdl::definitions::issuer_signed::IssuerSignedItemBytes;
use isomdl::definitions::x509::x5chain::X5CHAIN_COSE_HEADER_LABEL;
use isomdl::definitions::x509::X5Chain;
use isomdl::definitions::{CoseKey, DigestAlgorithm, DigestId, Mso, EC2Y};
use isomdl::issuance::mdoc::Mdoc;
use p256::ecdsa::{Signature, VerifyingKey};
use p256::pkcs8::EncodePublicKey;
use p256::NistP256;
use serde_json::Map;
use sha2::{Digest, Sha256};
use num_bigint::BigUint;
use num_traits::Zero;
use chrono::{DateTime, Datelike, FixedOffset, NaiveDate, NaiveDateTime, TimeZone, Utc};
use std::str;
use std::collections::{BTreeMap,HashSet};

static MDL_DOCTYPE: &str = "org.iso.18013.5.1.mDL";
static ISO_MDL_NAMESPACE: &str = "org.iso.18013.5.1";
static AAMVA_MDL_NAMESPACE: &str = "org.iso.18013.5.1.aamva";
static SUPPORTED_NAMESPACES: [&str; 2] = [ISO_MDL_NAMESPACE, AAMVA_MDL_NAMESPACE];

lazy_static! {
    static ref CRESCENT_CONFIG_KEYS: HashSet<&'static str> = {
        let mut set = HashSet::new();
        set.insert("alg");
        set.insert("credtype");
        set.insert("max_cred_len");
        set.insert("device_bound");
        set
    };
}

// Define the issuer's timezone as PST (UTC-8). Change this if needed (TODO: move to config)
const ISSUER_TIMEZONE_OFFSET_HOURS: i32 = -8; // US West Coast / PST (UTC-8)

#[derive(Parser, Debug)]
#[command(author, version, about)]
struct Args {
    /// JSON file containing the config
    #[arg(short = 'c', long = "config")]
    config: String,

    /// JSON file containing the mDL ISO claims
    #[arg(short = 'm', long = "mdl")]
    mdl: String,

    /// output JSON file containing the prover inputs
    #[arg(short = 'i', long = "prover_inputs")]
    prover_inputs: String,

    /// output JSON file containing the auxiliary data
    #[arg(short = 'a', long = "prover_aux")]
    prover_aux: String,
}

// Interpret the input as a bit string, convert to an integer where the
// leftmost bit in the string is interpreted as the LSB of the integer
// Behavior matches circomlib's Bits2Num function.
fn bits_to_num(bytes : &[u8]) -> BigUint {
    // Convert bytes to bit array
    let mut bitvec = vec![];
    for b in bytes {
        for i in (0..8).rev() {
            bitvec.push((b >> i) & 1);
        }
    }
    // Convert to integer
    let mut e = BigUint::from(1u32);
    let mut res = BigUint::from(0u32);
    for i in 0..248 {
        res += &e * BigUint::from(bitvec[i] as u32);
        e = BigUint::from(2u32)*e;  // e = 2*e
    }

    res
}

fn sha256_padding(prepad_m: &[u8]) -> Vec<u8> {
    let msg_length_bits = (prepad_m.len() * 8) as u32;
    
    // Start with prepad_m and add the 0x80 (128 in decimal) padding byte
    let mut padded_m = prepad_m.to_vec();
    padded_m.push(0x80);

    // Pad with zeros until the total length + 4 bytes (32-bit message length) is a multiple of 64 bytes (512 bits)
    while (padded_m.len() + 4) * 8 % 512 != 0 {
        padded_m.push(0);
    }

    // Append the message length as a 4-byte big-endian value
    padded_m.extend_from_slice(&msg_length_bits.to_be_bytes());

    padded_m
}

fn base64_decoded_size(encoded_len: usize) -> usize {
    encoded_len.div_ceil(4) * 3
}

fn ymd_to_timestamp(ymd: &str, is_bytes: bool, has_time: bool) -> Option<u64> {
    // Decode hex if necessary.
    let ymd_str = if is_bytes {
        hex::decode(ymd)
            .ok()
            .and_then(|decoded| String::from_utf8(decoded).ok())?
    } else {
        ymd.to_string()
    };

    // Determine the format string.
    let format_string = if has_time {
        "%Y-%m-%dT%H:%M:%SZ"
    } else {
        "%Y-%m-%d"
    };

    // Parse the date/time from the string.
    let naive_dt = NaiveDateTime::parse_from_str(&ymd_str, format_string).ok()?;

    // Reset time-of-day to midnight.
    let midnight = naive_dt.date().and_hms_opt(0, 0, 0).unwrap();

    // Build the correct FixedOffset.
    let offset_secs = ISSUER_TIMEZONE_OFFSET_HOURS * 3600;
    let fixed_offset = if offset_secs < 0 {
        FixedOffset::west_opt(-offset_secs)?
    } else {
        FixedOffset::east_opt(offset_secs)?
    };

    // Convert the naive datetime to a timezone-aware datetime.
    let dt_fixed = fixed_offset.from_local_datetime(&midnight).single()?;
    // Convert to UTC and return the timestamp.
    let dt_utc: DateTime<Utc> = dt_fixed.with_timezone(&Utc);
    Some(dt_utc.timestamp() as u64)
}

fn ymd_to_daystamp(ymd: &str) -> Option<i32> {
    let parsed_date = NaiveDate::parse_from_str(ymd, "%Y-%m-%d").ok()?;
    Some(parsed_date.num_days_from_ce())
}

#[derive(Debug)]
struct  ValueDigestInfo {
    value: String,
    id: DigestId,
    digest: Vec<u8>,
    preimage: ByteStr,
    encoded_l: usize,
    encoded_r: usize,
    identifier_l: usize,
    value_l: usize,
    value_r: usize,
}

/// Returns (encoded_l, encoded_r) as computed from tbs_data.
///
/// The CBOR format is:
/// - 2-digit hex for the digest id (e.g. "13" for 19) // FIXME: this assumes the id is < 23 (otherwise CBOR encodes it in 2 bytes)
/// - Literal "5820" for a 32-byte byte string indicator
/// - The 32-byte SHA-256 digest in hex (64 hex digits)
///
/// Then we find the position of this string in the hex-encoded tbs_data. Each byte is 2 hex digits,
/// so we convert the found index to a byte index (by dividing by 2) and subtract 1 (to adjust for a header).
/// Finally, encoded_r is computed as encoded_l + (length of cbored_digest in bytes).
pub fn compute_encoded_positions(
    tbs_data: &[u8],
    digest_id: DigestId,
    digest: &[u8],
) -> Result<(usize, usize), String> {
    // Build the "cbored_digest" string.
    // - Format: "{:02x}5820{}", where {:02x} is the digest id in 2-digit hex,
    //   "5820" is a literal string, and the digest is hex-encoded.
    // NOTE: bending over backward to convert the digest_id into a value accepted by format()
    //       Digest is defined as "pub struct DigestId(i32)" and provide no public accessor
    //       to the i32.
    let id_i32: i32 = serde_json::from_str(&serde_json::to_string(&digest_id).unwrap()).unwrap();
    let cbored_digest = format!("{:02x}5820{}", id_i32, hex::encode(digest));
    
    // Convert the entire tbs_data into a hex string.
    let tbs_data_hex = hex::encode(tbs_data);
    
    // Find the start position of cbored_digest within tbs_data_hex.
    // This position is in terms of hex characters.
    let pos = tbs_data_hex.find(&cbored_digest)
        .ok_or("cbored_digest not found in tbs_data")?;
    
    // Each byte is represented by 2 hex characters.
    // So, convert the position from hex characters to byte index and subtract 1.
    let encoded_l = pos / 2;

    // The length of cbored_digest in bytes is its length (in hex characters) divided by 2.
    let encoded_r = encoded_l + (cbored_digest.len() / 2);
    
    Ok((encoded_l, encoded_r))
}

/// Find the positions of the element identifier and value in the preimage.
/// Returns (identifier_l, identifier_r, value_l, value_r)
fn find_element_positions(preimage: &[u8], identifier: &str) -> Option<(usize, usize, usize, usize)> {
    // Encode the identifier as CBOR text string
    let identifier_bytes = {
        let mut v = Vec::new();
        let len = identifier.len();

        if len < 24 {
            v.push(0x60 | (len as u8)); // Major type 3 (text string)
        } else {
            panic!("Only supports identifier strings shorter than 24 bytes");
        }

        v.extend_from_slice(identifier.as_bytes());
        v
    };

    // Find the start of the elementIdentifier
    let identifier_l = preimage
        .windows(identifier_bytes.len())
        .position(|window| window == identifier_bytes.as_slice())?;

    let identifier_r = identifier_l + identifier_bytes.len();

    // Find the next string after identifier: "elementValue"
    let element_value_label = {
        let label = "elementValue";
        let mut v = Vec::new();
        v.push(0x60 | (label.len() as u8));
        v.extend_from_slice(label.as_bytes());
        v
    };

    let element_value_pos = preimage
        .windows(element_value_label.len())
        .position(|window| window == element_value_label.as_slice())?;

    let value_l = element_value_pos + element_value_label.len();
    let value_r = preimage.len();
    println!("identifier_l: {identifier_l}, identifier_r: {identifier_r}, value_l: {value_l}, value_r: {value_r}");
    Some((identifier_l, identifier_r, value_l, value_r))
}

/// Extract the text from a Value, which can be a Tag, Text, or Integer.
fn extract_text(value: Value) -> String {
    match value {
        Value::Tag(_, boxed) => extract_text(*boxed),
        Value::Text(s) => s,
        Value::Integer(i) => i128::from(i).to_string(),
        other => panic!("Expected Text, Integer, or Tag containing Text/Integer, got {other:?}"),
    }
}

/// Given an mdoc and a target element name, recompute the value digest,
/// compare it with the signed digest in the mso, and return detailed info.
pub(crate) fn find_value_digest_info(
    namespaces: &BTreeMap<String, NonEmptyVec<IssuerSignedItemBytes>>,
    mso: &Mso,
    tbs_data: &[u8],
    claim: &str,
) -> Option<ValueDigestInfo> {

    let mut info = ValueDigestInfo {
        value: String::new(),
        id: DigestId::new(0),
        digest: Vec::new(),
        preimage: ByteStr::from(Vec::new()),
        encoded_l: 0,
        encoded_r: 0,
        identifier_l: 0,
        value_l: 0,
        value_r: 0,
    };

    // Iterate over each supported namespace.
    for &ns in SUPPORTED_NAMESPACES.iter() {
        if let Some(items) = namespaces.get(ns) {
            // items is a NonEmptyVec<IssuerSignedItemBytes>; iterate over its items.
            for item in items.iter() {
                if item.as_ref().element_identifier != claim {
                    continue;
                }
                println!("found claim: {claim}");
                println!("item: {item:?}");

                info.value = extract_text(item.as_ref().element_value.clone());
                println!("value: {:?}", info.value);
                info.id = item.as_ref().digest_id;
                info.preimage = ByteStr::from(isomdl::cbor::to_vec(item).expect("unable to encode IssuerSigned as cbor bytes"));
                let (identifier_l, _identifier_r, value_l, value_r) = find_element_positions(info.preimage.as_ref(), claim)
                    .expect("Unable to find the element positions in preimage");
                info.identifier_l = identifier_l;
                // Note: should we return info.identifier_r = _identifier_r? We currently calculate it based on the known length identifier value
                info.value_l = value_l;
                info.value_r = value_r;
                let mut hasher = Sha256::new();
                hasher.update(&info.preimage);
                let recomputed_value_digest = hasher.finalize().to_vec();
                // print recomputed digest as hex
                println!("Recomputed digest: {}", hex::encode(&recomputed_value_digest));
                let ns_digests = mso.value_digests.get(ns)
                    .ok_or(format!("Namespace {ns} not found")).unwrap();
                let signed_value_digest = ns_digests.get(&info.id)
                    .ok_or(format!("Signed value digest not found for digest id {:?}", info.id)).unwrap();
                println!("signed_value_digest: {:?}", hex::encode(signed_value_digest));
                // Compare recomputed digest with the signed digest.
                if recomputed_value_digest != signed_value_digest.as_ref()  {
                    println!("Digest mismatch");
                    println!("Recomputed: {}", hex::encode(&recomputed_value_digest));
                    println!("Signed    : {}", hex::encode(signed_value_digest));
                    panic!("Digest mismatch");
                } else {
                    println!("Digest: {}", hex::encode(&recomputed_value_digest));
                }
                info.digest = signed_value_digest.as_ref().to_vec();
                let encoded_pos = compute_encoded_positions(tbs_data, info.id, &info.digest).unwrap();
                info.encoded_l = encoded_pos.0;
                info.encoded_r = encoded_pos.1;
                return Some(info)
            }
        }
    }
    
    println!("Claim not found: {claim}");
    None
}

// TODO: see the check_config() function in the python script; more stuff to implement
fn check_config(config: &serde_json::Map<String, serde_json::Value>) {
    // check the credtype
    let credtype = config["credtype"].as_str().unwrap();
    if credtype != "mdl" {
        panic!("Invalid credtype: {credtype}");
    }

    // check the signature alg
    let alg = config["alg"].as_str().unwrap();
    if alg != "ES256" {
        panic!("Unsupported alg: {alg}");
    }

    // make sure max_cred_len exists
    let max_cred_len = config["max_cred_len"].as_u64().unwrap();
    if max_cred_len == 0 {
        panic!("Invalid max_cred_len, needs to be > 0: {max_cred_len}");
    }
}

// copied from JWT's proverinput.rs
fn pack_string_to_int_unquoted(s: &str, n_bytes: usize) -> Result<String, Box<std::io::Error>> {
    // Must match function "RevealDomainOnly" in match_claim.circom

    //First convert "s" to bytes and pad with zeros
    let s_bytes = s.bytes();
    if s_bytes.len() > n_bytes {
        panic!("String to large to convert to integer of n_bytes = {n_bytes}");
    }
    let mut s_bytes = s_bytes.collect::<Vec<u8>>();
    for _ in 0 .. n_bytes - s_bytes.len() {
        s_bytes.push(0x00);
    }
    // Convert to an integer with base-256 digits equal to s_bytes
    let mut n = BigUint::zero();
    let twofiftysix = BigUint::from(256_u32);// from_u32(256);
    for i in 0..s_bytes.len() {
        assert!(i < u32::MAX as usize);
        n += s_bytes[i] * twofiftysix.pow(i as u32);
    }
    
    Ok(n.to_str_radix(10))
}


fn main() {
    let args = Args::parse();

    // read and parse the config file
    let config_file = std::fs::read_to_string(&args.config).unwrap();
    let config_value: serde_json::Value = serde_json::from_str(&config_file).unwrap();
    let config = config_value.as_object().expect("Invalid config file");
    check_config(config);

    let mdl_cbor = std::fs::read(&args.mdl).unwrap();
    let mdoc = cbor::from_slice::<Mdoc>(
        &mdl_cbor)
        .map_err(|_| "Failed to parse mDL")
        .unwrap();

    let doc_type = mdoc.doc_type;
    println!("doc_type: {doc_type}\n");
    if doc_type != MDL_DOCTYPE {
        panic!("Invalid mDL doc type: {doc_type}");
    }
    
    let mso = mdoc.mso;
    // make sure the digest alg is SHA256. No compare or public accessor on the DigestAlgorithm enum, so
    // I need to serialize it to compare its value.
    if !matches!(mso.digest_algorithm, DigestAlgorithm::SHA256) {
        panic!("Unsupported MSO digest algorithm: {:?}, expected SHA-256", mso.digest_algorithm)
    }
    // TODO: we might need these digests in the future, for selective disclosure
    let _value_digests = &mso.value_digests;

    let namespaces = mdoc.namespaces;
    for (key, value) in namespaces.iter() {
        if !SUPPORTED_NAMESPACES.contains(&key.as_str()) {
            panic!("Invalid mDL namespace: {key}");
        }
        println!("{} namespace claim count: {}\n", key, value.len());
    }
    
    let issuer_auth = mdoc.issuer_auth;

    // issuer_auth fields
    let unprotected_header = issuer_auth.unprotected.clone();
    let x5chain = unprotected_header
        .rest
        .iter()
        .find(|(label, _)| label == &Label::Int(X5CHAIN_COSE_HEADER_LABEL))
        .map(|(_, value)| value.to_owned())
        .map(X5Chain::from_cbor)
        .unwrap()
        .unwrap();

    let issuer_pub_key = x5chain.end_entity_public_key::<NistP256>().unwrap();
    let _pem = issuer_pub_key
        .to_public_key_pem(Default::default())
        .unwrap();

    // per mDL spec, aad is empty
    let empty_aad = Vec::<u8>::new();
    let tbs_data = issuer_auth.inner.tbs_data(&empty_aad);

    // convert tbs_data to a vector of integers
    let tbs_data_ints = tbs_data.to_vec();
    println!("tbs_data_ints length: {:?}\n", tbs_data_ints.len());

    // convert header and payload to UTF-8 integers in base-10 (e.g., 'e' -> 101, 'y' -> 121, ...)
    let padded_m = sha256_padding(&tbs_data_ints);
    let msg_len_after_sha2_padding = padded_m.len();
    println!("msg_len_after_SHA2_padding: {msg_len_after_sha2_padding:?}\n");

    let config_max_cred_len = config["max_cred_len"].as_u64().unwrap() as usize;
    if tbs_data_ints.len() > config_max_cred_len {
        println!(
            "Error: mDL too large. Current mDL header + payload is {} bytes, but maximum length supported is {} bytes.",
            tbs_data_ints.len(),
            base64_decoded_size(config_max_cred_len)
        );
        println!(
            "The config file value `max_cred_len` would have to be increased to {} bytes (currently config['max_cred_len'] = {})",
            tbs_data_ints.len() + 64,
            config_max_cred_len
        );
        std::process::exit(-1);
    }

    let mut padded_m_extended = Vec::with_capacity(config_max_cred_len);
    padded_m_extended.extend_from_slice(&padded_m);
    padded_m_extended.resize(config_max_cred_len, 0);

    let valid_until_prefix = "6a76616c6964556e74696cc074"; // 6a: text(10), 7661...696c: "validUntil", c0: date, 74: text(20)
    let tbs_data_hex = hex::encode(&tbs_data);
    let valid_until_prefix_pos = tbs_data_hex.find(valid_until_prefix).unwrap();
    let valid_until_pos = valid_until_prefix_pos + valid_until_prefix.len();
    let valid_until_data = &tbs_data_hex[valid_until_pos..valid_until_pos + 40];
    let valid_until_unix_timestamp = ymd_to_timestamp(valid_until_data, true, true).unwrap();
    println!("valid_until_unix_timestamp: {valid_until_unix_timestamp}");
    
    // begin output of prover and auxiliary inputs
    let mut prover_inputs = Map::new();
    let mut prover_aux = Map::new();
    prover_inputs.insert("message".to_string(), serde_json::json!(padded_m_extended));
    prover_inputs.insert("valid_until_value".to_string(), serde_json::json!(valid_until_unix_timestamp));
    let valid_until_prefix_l = valid_until_prefix_pos / 2;
    prover_inputs.insert("valid_until_prefix_l".to_string(), valid_until_prefix_l.into());
    let valid_until_prefix_r = valid_until_prefix_l + valid_until_prefix.len() / 2;
    prover_inputs.insert("valid_until_prefix_r".to_string(), valid_until_prefix_r.into());
    
    // process claims listed in the config
    let keys = config.keys();
    for key in keys {
        if CRESCENT_CONFIG_KEYS.contains(key.as_str()) {
            continue;
        }
        let claim_name = key.as_str();
        let entry = config[claim_name].as_object().ok_or(format!("Config file entry for claim {claim_name}, does not have object type")).unwrap();
        let claim_type = entry["type"].as_str().ok_or(format!("Config file entry for claim {claim_name}, is missing 'type'")).unwrap();
        let reveal = entry.get("reveal").and_then(|v| v.as_bool()).unwrap_or(false);
        let reveal_digest = entry.get("reveal_digest").and_then(|v| v.as_bool()).unwrap_or(false);
        let max_claim_byte_len = entry["max_claim_byte_len"].as_u64().ok_or(format!("Config file entry for claim {claim_name} does not have a valid u64 'max_claim_byte_len'")).map(|v| v as usize).unwrap();

        if !reveal && !reveal_digest {
            println!("Claim {claim_name} is not revealed or reveal_digest: skipping");
            continue;
        }

        println!("\nProcessing {} ({}) for {}", claim_name, claim_type, if reveal { "reveal" } else { "reveal_digest" });

        let claim_info = find_value_digest_info(&namespaces, &mso, &tbs_data, claim_name).unwrap();
        println!("claim_info ({claim_name}): {claim_info:?}");
        prover_inputs.insert(format!("{claim_name}_id").to_string(), serde_json::json!(claim_info.id));
        let claim_value_str = claim_info.value.as_str();

        let claim_preimage = sha256_padding(claim_info.preimage.as_ref());
        if claim_preimage.len() != 128 { // FIXME: don't hardcode this value. Currently correct for the mDL we generate, but not in general
            panic!("Invalid {}_preimage length: {}; expected 128 (hardcoded in circom circuit)", claim_name, claim_preimage.len());
        }
        prover_inputs.insert(format!("{claim_name}_preimage").to_string(), serde_json::json!(claim_preimage));
        prover_inputs.insert(format!("{claim_name}_encoded_l").to_string(), serde_json::json!(claim_info.encoded_l));
        prover_inputs.insert(format!("{claim_name}_encoded_r").to_string(), serde_json::json!(claim_info.encoded_r));
        prover_inputs.insert(format!("{claim_name}_identifier_l").to_string(), serde_json::json!(claim_info.identifier_l));

        if reveal {
            match claim_type {
                "string" => {
                    // for string values, we skip the first CBOR byte (0x60) which indicates the string length, to only compare the claim value
                    // FIXME: not true in general, only for short strings!
                    let value_l = claim_info.value_l + 1;
                    prover_inputs.insert(format!("{claim_name}_value_l").to_string(), serde_json::json!(value_l));
                    prover_inputs.insert(format!("{claim_name}_value_r").to_string(), serde_json::json!(claim_info.value_r));
                    let claim_value = pack_string_to_int_unquoted(claim_value_str, max_claim_byte_len).unwrap();
                    prover_inputs.insert(format!("{claim_name}_value").to_string(), serde_json::json!(claim_value));
                },
                "date" => {
                    // we don't need the value_l and value_r for date
                    let claim_value = ymd_to_daystamp(claim_value_str).unwrap();
                    prover_inputs.insert(format!("{claim_name}_value").to_string(), serde_json::json!(claim_value));
                },
                "integer" => {
                    // encode integer directly
                    prover_inputs.insert(format!("{claim_name}_value").to_string(), serde_json::json!(claim_value_str));
                },
                // TODO: add support for other claim types
                &_ => {
                    panic!("Unsupported claim type: {claim_type}");
                }
            };
        } else if reveal_digest {
            // Add the preimage to the prover auxiliary data
            match claim_type {
                    "integer" => {
                        prover_aux.insert(claim_name.to_string(), serde_json::json!(claim_value_str));
                    }
                    "string" => {
                        if claim_value_str.len() > max_claim_byte_len as usize {
                            panic!("Claim too large ({} bytes), largest allowed by configuration is {} bytes", claim_value_str.len(), max_claim_byte_len);
                        }
                        // for string values, we skip the first CBOR byte (0x60) which indicates the string length, to only compare the claim value
                        // FIXME: not true in general, only for short strings!
                        let value_l = claim_info.value_l + 1;
                        prover_inputs.insert(format!("{claim_name}_value_l").to_string(), serde_json::json!(value_l));
                        prover_inputs.insert(format!("{claim_name}_value_r").to_string(), serde_json::json!(claim_info.value_r));
                        prover_aux.insert(claim_name.to_string(), serde_json::json!(claim_value_str));
                    }
                    _ => {
                        // TODO: date?
                        panic!("Can only reveal number types and string types as a single field element for now. See also `reveal_bytes`.")
                    }
                }
        }
    }

    // extract the signature from the issuer_auth
    let signature_bytes = issuer_auth.signature.clone();

    // sanity check: verify the signature
    let verification_result =
            issuer_auth
            .verify::<VerifyingKey, Signature>(&issuer_pub_key, None, None);
    if !verification_result.is_success() {
        panic!("Error: issuer signature verification failed: {}", verification_result.into_result().err().unwrap());
    }

    // process the signature
    // See https://www.rfc-editor.org/rfc/rfc7515#appendix-A.3.1 for ECDSA encoding details, the signature is R||S
    // this code assumes |R|==|S|
    let sig_len = signature_bytes.len();
    if sig_len % 2 != 0 {
        panic!("Invalid signature length: {sig_len}");
    }
    // signature is not required by the circuit, but it is required for the signature verification pre-computations
    // by the precompEcdsa script. That script extracts the signature from the prover_input.json file.
    prover_inputs.insert("signature".to_string(), serde_json::json!(signature_bytes));

    // process the issuer public key
    let issuer_key_bytes = issuer_pub_key.to_sec1_bytes();
    if issuer_key_bytes[0] != 0x04 {
        panic!("Invalid serialized issuer public key format: {}, expected uncompressed marker 0x04", issuer_key_bytes[0]);
    }
    if issuer_key_bytes.len() != 65 {
        panic!("Invalid serialized issuer public key length: {}", issuer_key_bytes.len());
    }
    prover_inputs.insert("pubkey".to_string(), serde_json::json!(&issuer_key_bytes));
    let mut digest = Sha256::digest(&issuer_key_bytes[1..]).to_vec();    // skip hashing the first byte
    digest = digest[0..digest.len()-1].to_vec();    // truncate digest to 248 bits
    let pubkey_hash = bits_to_num(&digest);
    prover_inputs.insert("pubkey_hash".to_string(), serde_json::json!(pubkey_hash.to_str_radix(10)));

    prover_inputs.insert("message_bytes".to_string(), tbs_data_ints.len().into());
    println!("Number of SHA blocks to hash: {msg_len_after_sha2_padding}\n");

    // If device bound, include the device public key in the prover inputs
    if config["device_bound"].as_bool().is_some_and(|x| x) {
        let device_key = mso.device_key_info.device_key;
        assert!(device_key.signature_algorithm() == Some(Algorithm::ES256), "Only device keys with the ES256 algorithm are supported");

        let (mut device_key_x, device_key_y)  = match device_key {
            CoseKey::EC2 { x, y, .. } => (x, y),
            _ => panic!("Unsupported curve type, expected EC2 (https://www.rfc-editor.org/rfc/rfc9053.html#name-elliptic-curve-keys)")
        };
        println!("device_key.x = {device_key_x:?}");
        println!("device_key.y = {device_key_y:?}");
        prover_inputs.insert("device_key_x".to_string(), serde_json::json!(device_key_x));
        // device_key_x is Vec<u8>, device_key_y is EC2Y
        let device_pub_key_x = BigUint::from_bytes_be(&device_key_x);
        let device_pub_key_y = match device_key_y {
            EC2Y::Value(ref y_bytes) => BigUint::from_bytes_be(y_bytes),
            EC2Y::SignBit(_) => panic!("EC2Y::SignBit is not supported for this operation"),
        };
        prover_aux.insert("device_pub_x".to_string(), serde_json::json!(device_pub_key_x.to_str_radix(10)));
        prover_aux.insert("device_pub_y".to_string(), serde_json::json!(device_pub_key_y.to_str_radix(10)));       

        device_key_x.reverse();

        // Helper function used to encode bytes as field elements
        let bytes_to_int = |bytes: &[u8]| -> String {
            let mut a = BigUint::zero();
            for i in 0..bytes.len() {
                a += BigUint::from(bytes[i] as u64) * BigUint::from(256u64).pow(i as u32);
            }
            a.to_str_radix(10)
        };    

        let device_key_0 = bytes_to_int(&device_key_x[0..16]);
        let device_key_1 = bytes_to_int(&device_key_x[16..32]);
        println!("device_key_0_value: {device_key_0:?}");
        println!("device_key_1_value: {device_key_1:?}");
        prover_inputs.insert("device_key_0_value".to_string(), serde_json::json!(device_key_0));
        prover_inputs.insert("device_key_1_value".to_string(), serde_json::json!(device_key_1));

        let device_key_prefix = "6d6465766963654b6579496e666fa1696465766963654b6579a401022001215820"; 
        // The prefix is: 
        //   6d                                                #     text(13)
        //      6465766963654b6579496e666f                     #       "deviceKeyInfo"
        //   a1                                                #     map(1)
        //      69                                             #       text(9)
        //         6465766963654b6579                          #         "deviceKey"
        //      a4                                             #       map(4)
        //         01                                          #         unsigned(1)
        //         02                                          #         unsigned(2)
        //         20                                          #         negative(-1)
        //         01                                          #         unsigned(1)
        //         21                                          #         negative(-2)
        //         58 20                                       #         bytes(32)

        let device_key_prefix_l = tbs_data_hex.find(device_key_prefix).unwrap()/2;
        let device_key_prefix_r = device_key_prefix_l + device_key_prefix.len()/2;
        prover_inputs.insert("device_key_x_prefix_l".to_string(), serde_json::json!(device_key_prefix_l));
        prover_inputs.insert("device_key_x_prefix_r".to_string(), serde_json::json!(device_key_prefix_r));
    }

    println!("prover_inputs path: {}", args.prover_inputs);
    println!("prover_aux path: {}", args.prover_aux);

    // save prover_inputs to a file
    let prover_inputs_json = serde_json::to_string_pretty(&prover_inputs).unwrap();
    std::fs::write(&args.prover_inputs, prover_inputs_json).unwrap();
    println!("Prover inputs saved to: {}\n", args.prover_inputs);

    // save the auxiliary data to a file
    let prover_aux_json = serde_json::to_string_pretty(&prover_aux).unwrap();
    println!("Prover auxiliary data: {prover_aux_json}");
    println!("output file: {}", args.prover_aux);
    std::fs::write(&args.prover_aux, prover_aux_json).unwrap();
    println!("Prover auxiliary data saved to: {}\n", args.prover_aux);

}
